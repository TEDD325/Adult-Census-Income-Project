{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import DataReader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 주피터 노트북 환경에서 현재 작업 디렉토리 경로를 얻습니다.\n",
    "current_dir_path = os.getcwd()\n",
    "\n",
    "# info.yaml 파일의 경로를 현재 작업 디렉토리를 기반으로 구성합니다.\n",
    "yaml_file_path = os.path.join(current_dir_path, 'info.yaml')\n",
    "target_col = 'target'\n",
    "\n",
    "ROOT_PATH = current_dir_path\n",
    "\n",
    "train, test, label = DataReader.read_from_db(\n",
    "    yaml_file_path=yaml_file_path,\n",
    "    table_name=\"adult_income\",\n",
    "    label_col_name=target_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: \n",
      "Index(['workclass', 'education', 'marital.status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native.country'],\n",
      "      dtype='object')\n",
      "\n",
      " Numeric Columns: \n",
      "Index(['index', 'id', 'age', 'fnlwgt', 'education.num', 'capital.gain',\n",
      "       'capital.loss', 'hours.per.week'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_cat_columns = train.select_dtypes(include='object').columns\n",
    "train_num_columns = train.select_dtypes(exclude='object').columns\n",
    "\n",
    "print('Categorical Columns: \\n{}\\n\\n Numeric Columns: \\n{}\\n'.format(train_cat_columns,train_num_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age, education_num, hours.per.week 이 target과 상대적으로 큰 상관관계 보임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = train.columns.str.replace('.','_')\n",
    "test.columns = test.columns.str.replace('.','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('fnlwgt',axis=1,inplace=True)\n",
    "test.drop('fnlwgt',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass         0\n",
      "occupation        0\n",
      "native_country    0\n",
      "dtype: int64\n",
      "occupation\n",
      "Exec-managerial      2113\n",
      "Craft-repair         2101\n",
      "Prof-specialty       2085\n",
      "Adm-clerical         1893\n",
      "Others               1843\n",
      "Sales                1829\n",
      "Other-service        1677\n",
      "Machine-op-inspct    1040\n",
      "Transport-moving      785\n",
      "Handlers-cleaners     695\n",
      "Farming-fishing       508\n",
      "Tech-support          475\n",
      "Protective-serv       350\n",
      "Priv-house-serv        83\n",
      "Armed-Forces            3\n",
      "Name: count, dtype: int64\n",
      "native_country\n",
      "United-States                 15976\n",
      "Mexico                          355\n",
      "Philippines                     108\n",
      "Germany                          75\n",
      "Canada                           63\n",
      "Puerto-Rico                      59\n",
      "El-Salvador                      58\n",
      "Cuba                             49\n",
      "India                            47\n",
      "England                          46\n",
      "Jamaica                          42\n",
      "China                            40\n",
      "South                            39\n",
      "Italy                            38\n",
      "Dominican-Republic               38\n",
      "Columbia                         37\n",
      "Guatemala                        36\n",
      "Poland                           35\n",
      "Japan                            33\n",
      "Vietnam                          32\n",
      "Taiwan                           28\n",
      "Haiti                            23\n",
      "Nicaragua                        20\n",
      "Portugal                         20\n",
      "Ecuador                          19\n",
      "Ireland                          18\n",
      "Iran                             17\n",
      "Peru                             17\n",
      "Greece                           14\n",
      "France                           14\n",
      "Cambodia                         11\n",
      "Laos                             10\n",
      "Trinadad&Tobago                  10\n",
      "Yugoslavia                        9\n",
      "Hong                              9\n",
      "Honduras                          7\n",
      "Outlying-US(Guam-USVI-etc)        7\n",
      "Hungary                           7\n",
      "Scotland                          7\n",
      "Thailand                          6\n",
      "Holand-Netherlands                1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 'workclass' 열의 결측값을 'Never-worked'로 대체\n",
    "train['workclass'] = train['workclass'].apply(lambda x: 'Never-worked' if x is None else x)\n",
    "\n",
    "# 'occupation' 열의 결측값을 'Others'로 대체\n",
    "# 'occupation' 열에서 결측값이 의미 있는 값으로 간주될 수 있음을 반영\n",
    "train['occupation'] = train['occupation'].apply(lambda x: 'Others' if x is None else x)\n",
    "\n",
    "# 'native.country'와 race의 상관관계가 큼을 확인.\n",
    "# 'native.country' 열의 결측값을 race에 따른 native.country의 분포를 참조하여 채운다.\n",
    "\n",
    "# 각 'race'에 대한 'native.country'의 가장 흔한 값 찾기\n",
    "most_common_countries_per_race = train.groupby('race')['native_country'].apply(lambda x: x.mode().iloc[0])\n",
    "\n",
    "# 'native.country'의 결측값을 해당 'race'의 가장 흔한 값으로 채우기\n",
    "for race, common_country in most_common_countries_per_race.items():\n",
    "    condition = (train['race'] == race) & (train['native_country'].isnull())\n",
    "    train.loc[condition, 'native_country'] = common_country\n",
    "\n",
    "# 변경 사항 확인을 위한 출력\n",
    "print(train[['workclass', 'occupation', 'native_country']].isnull().sum())\n",
    "\n",
    "occupation_counts = train['occupation'].value_counts()\n",
    "print(occupation_counts)\n",
    "\n",
    "native_country_counts = train['native_country'].value_counts()\n",
    "print(native_country_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = train.select_dtypes(include='object').columns\n",
    "num_columns = train.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train, label,\n",
    "                                                      test_size=0.3,\n",
    "                                                      shuffle=True,\n",
    "                                                      stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reset_index(drop=True)\n",
    "x_valid = x_valid.reset_index(drop=True)\n",
    "x_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass         0\n",
      "occupation        0\n",
      "native_country    0\n",
      "dtype: int64\n",
      "occupation\n",
      "Prof-specialty       2055\n",
      "Craft-repair         1998\n",
      "Exec-managerial      1953\n",
      "Adm-clerical         1877\n",
      "Sales                1821\n",
      "Other-service        1618\n",
      "Machine-op-inspct     962\n",
      "Transport-moving      812\n",
      "Handlers-cleaners     675\n",
      "Farming-fishing       486\n",
      "Tech-support          453\n",
      "Protective-serv       299\n",
      "Priv-house-serv        66\n",
      "Armed-Forces            6\n",
      "Name: count, dtype: int64\n",
      "native_country\n",
      "United-States                 13777\n",
      "Mexico                          288\n",
      "Philippines                      90\n",
      "Germany                          62\n",
      "Canada                           58\n",
      "Puerto-Rico                      55\n",
      "India                            53\n",
      "El-Salvador                      48\n",
      "Cuba                             46\n",
      "England                          44\n",
      "South                            41\n",
      "Jamaica                          39\n",
      "Italy                            35\n",
      "China                            35\n",
      "Vietnam                          35\n",
      "Dominican-Republic               32\n",
      "Japan                            29\n",
      "Guatemala                        28\n",
      "Iran                             26\n",
      "Poland                           25\n",
      "Taiwan                           23\n",
      "Columbia                         22\n",
      "Haiti                            21\n",
      "Portugal                         17\n",
      "Greece                           15\n",
      "France                           15\n",
      "Nicaragua                        14\n",
      "Peru                             14\n",
      "Thailand                         12\n",
      "Hong                             11\n",
      "Trinadad&Tobago                   9\n",
      "Ecuador                           9\n",
      "Laos                              8\n",
      "Cambodia                          8\n",
      "Yugoslavia                        7\n",
      "Outlying-US(Guam-USVI-etc)        7\n",
      "Hungary                           6\n",
      "Honduras                          6\n",
      "Ireland                           6\n",
      "Scotland                          5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_test['workclass'] = x_test['workclass'].apply(lambda x: 'Never-worked' if x is None else x)\n",
    "\n",
    "# 'occupation' 열의 결측값을 'Others'로 대체\n",
    "# 'occupation' 열에서 결측값이 의미 있는 값으로 간주될 수 있음을 반영\n",
    "x_test['occupation'] = x_test['occupation'].apply(lambda x: 'Others' if x is None else x)\n",
    "\n",
    "# 'native.country'와 race의 상관관계가 큼을 확인.\n",
    "# 'native.country' 열의 결측값을 race에 따른 native.country의 분포를 참조하여 채운다.\n",
    "\n",
    "# 각 'race'에 대한 'native.country'의 가장 흔한 값 찾기\n",
    "most_common_countries_per_race = x_test.groupby('race')['native_country'].apply(lambda x: x.mode().iloc[0])\n",
    "\n",
    "# 'native.country'의 결측값을 해당 'race'의 가장 흔한 값으로 채우기\n",
    "for race, common_country in most_common_countries_per_race.items():\n",
    "    condition = (x_test['race'] == race) & (x_test['native_country'].isnull())\n",
    "    x_test.loc[condition, 'native_country'] = common_country\n",
    "\n",
    "# 변경 사항 확인을 위한 출력\n",
    "print(x_test[['workclass', 'occupation', 'native_country']].isnull().sum())\n",
    "\n",
    "occupation_counts = x_test['occupation'].value_counts()\n",
    "print(occupation_counts)\n",
    "\n",
    "native_country_counts = x_test['native_country'].value_counts()\n",
    "print(native_country_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train[num_columns] = scaler.fit_transform(x_train[num_columns])\n",
    "x_valid[num_columns] = scaler.transform(x_valid[num_columns])\n",
    "x_test[num_columns]  = scaler.transform(x_test[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (12236, 1), indices imply (12236, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m ohe\u001b[38;5;241m.\u001b[39mfit(pd\u001b[38;5;241m.\u001b[39mconcat([x_train[cat_columns], x_valid[cat_columns], x_test[cat_columns]]))\n\u001b[1;32m      7\u001b[0m ohe_columns \u001b[38;5;241m=\u001b[39m ohe\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[0;32m----> 9\u001b[0m new_x_train_cat \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mohe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcat_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mohe_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m new_x_valid_cat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(ohe\u001b[38;5;241m.\u001b[39mtransform(x_valid[cat_columns]), columns\u001b[38;5;241m=\u001b[39mohe_columns)\n\u001b[1;32m     11\u001b[0m new_x_test_cat  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(ohe\u001b[38;5;241m.\u001b[39mtransform(x_test[cat_columns]), columns\u001b[38;5;241m=\u001b[39mohe_columns)\n",
      "File \u001b[0;32m~/miniconda3/envs/income_project/lib/python3.11/site-packages/pandas/core/frame.py:856\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    848\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    849\u001b[0m             arrays,\n\u001b[1;32m    850\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    866\u001b[0m         {},\n\u001b[1;32m    867\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    871\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/income_project/lib/python3.11/site-packages/pandas/core/internals/construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    334\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/income_project/lib/python3.11/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (12236, 1), indices imply (12236, 100)"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# ohe.fit(x_train[cat_columns])\n",
    "ohe.fit(pd.concat([x_train[cat_columns], x_valid[cat_columns], x_test[cat_columns]]))\n",
    "ohe_columns = ohe.get_feature_names_out()\n",
    "\n",
    "new_x_train_cat = pd.DataFrame(ohe.transform(x_train[cat_columns]), columns=ohe_columns)\n",
    "new_x_valid_cat = pd.DataFrame(ohe.transform(x_valid[cat_columns]), columns=ohe_columns)\n",
    "new_x_test_cat  = pd.DataFrame(ohe.transform(x_test[cat_columns]), columns=ohe_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "income_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
